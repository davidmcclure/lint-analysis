{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.style.use('seaborn-muted')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tb = TextBlob(text)\n",
    "    return [[str(t) for t in s.words] for s in tb.sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_offset(seq):\n",
    "    \"\"\"Yield (item, 0-1 offset).\n",
    "    \"\"\"\n",
    "    size = len(seq)\n",
    "    for i, item in enumerate(seq):\n",
    "        offset = i / (size - 1) if (size - 1) else 0\n",
    "        yield item, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_bin(seq, bin_count):\n",
    "    \"\"\"Yield (item, bin)\n",
    "    \"\"\"\n",
    "    for item, offset in zip_offset(seq):\n",
    "        bin = math.floor(offset * bin_count) if offset < 1 else bin_count - 1\n",
    "        yield item, bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_storycorps(path):\n",
    "    with open(path) as fh:\n",
    "        data = ujson.load(fh)\n",
    "        for url, md in data.items():\n",
    "            if len(md.get('written_summary', '')) > 1000:\n",
    "                tokens = tokenize(md['written_summary'])\n",
    "                yield Document(url, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    \n",
    "    def __init__(self, id, sents):\n",
    "        self.id = id\n",
    "        self.sents = sents\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '%s<%d sentences>' % (self.__class__.__name__, len(self.sents))\n",
    "    \n",
    "    def tokens(self):\n",
    "        return [t.lower() for s in self.sents for t in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    @classmethod\n",
    "    def from_storycorps(cls, path):\n",
    "        return cls(list(read_storycorps(path)))\n",
    "    \n",
    "    def __init__(self, docs):\n",
    "        self.docs = docs\n",
    "        \n",
    "    def token_counts(self):\n",
    "        return Counter([\n",
    "            token for doc in self.docs \n",
    "            for token in doc.tokens()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Corpus.from_storycorps('../../data/story_corps_archive_content.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "667"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c.docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = c.token_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4645),\n",
       " ('and', 4094),\n",
       " ('to', 2979),\n",
       " ('in', 2960),\n",
       " ('of', 2618),\n",
       " ('a', 2289),\n",
       " ('her', 1783),\n",
       " ('i', 1501),\n",
       " ('was', 1454),\n",
       " ('he', 1432)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [t for t, _ in counts.most_common(1000)]\n",
    "vtoi = {v: i for i, v in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_counts = np.zeros((len(vocab), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 667/667 [00:00<00:00, 3500.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(c.docs):\n",
    "    for token, bi in zip_bin(doc.tokens(), bin_counts.shape[1]):\n",
    "        if token in vtoi:\n",
    "            bin_counts[vtoi[token]][bi] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1672.50it/s]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for vi, token in enumerate(tqdm(vocab)):\n",
    "    for bi in range(bin_counts.shape[1]):\n",
    "        \n",
    "        b_total = bin_counts[:,bi].sum()\n",
    "        \n",
    "        c_obs = bin_counts[vi][bi]\n",
    "        c_exp = bin_counts[vi].sum() / bin_counts.shape[1]\n",
    "        \n",
    "        s, _ = stats.power_divergence(\n",
    "            [c_obs, b_total-c_obs],\n",
    "            [c_exp, b_total-c_exp],\n",
    "            lambda_='log-likelihood',\n",
    "        )\n",
    "        \n",
    "        rows.append((token, bi, c_obs-c_exp, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows, columns=('token', 'bin', 'delta', 'score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in interview november conducted interviews my this interviewed about 16 2016 2015 born was 15 grandfather i han 2017 his\n",
      "the his and during aircraft talks humor to as comfortable he a smart transition ability amazing sense adults soon being\n",
      "he also hardest together they the and to under she been which as nuckolls festival why given of has poor\n",
      "end artists same strong strength bomb base loves forties for training 1940s presidential election ma think presented street gave minute\n",
      "places organizations keywords participants n/a university school thegreatlisten2016 san texas new music marriage united war ca washington folk love il\n"
     ]
    }
   ],
   "source": [
    "for bi in range(bin_counts.shape[1]):\n",
    "    bdf = df[(df.bin==bi) & (df.delta>0)].sort_values('score', ascending=False)\n",
    "    print(' '.join(bdf.head(20).token))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
